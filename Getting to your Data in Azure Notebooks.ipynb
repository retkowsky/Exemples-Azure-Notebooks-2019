{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting to your Data in Azure Notebooks\n",
    "Jupyter provides the basis of the Azure Notebooks user experience. But it doesn't provide us any data. This notebook provides samples of how you might retrieve data to use from within your own notebooks.\n",
    "\n",
    "There are many ways to get your data in your notebooks ranging from using curl or leveraging the [Azure](http://pypi.python.org/pypi/azure) package to access a variety of data all while working from a Jupyter Notebook. See the table of contents below to jump to a particular example.\n",
    "\n",
    "## Table of Contents\n",
    "- [Use curl to retrieve a file from GitHub](#curl)\n",
    "- [Interacting with Azure Blobs](#blobs)\n",
    "- [Using Azure Table Storage](#tablestorage)\n",
    "- [Providing Read Only Access to Azure Storage through Shared Access Signatures](#sharedaccess)\n",
    "- [Cleaning up created blobs and tables](#cleanup)\n",
    "- [Using SQL](#usingsql)\n",
    "- [Other Resources](#otherways)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use `curl` to retrieve a file from GitHub <a name=\"curl\"></a> \n",
    "\n",
    "We can call bash commands by starting our line with a `!`. In this way we can just curl a file down from the internet, like this csv about oil prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  5190  100  5190    0     0  30005      0 --:--:-- --:--:-- --:--:-- 30174\n"
     ]
    }
   ],
   "source": [
    "!curl -L https://raw.githubusercontent.com/petroleum101/figures/db46e7f48b8aab67a0dfe31696f6071fb7a84f1e/oil_price/oil_price.csv -o oil_price.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, if we wanted to do something with it, we might choose to load it into pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>BP us dollar of the day</th>\n",
       "      <th>US Domestic Oil Price (US $) PET_F000000__3_A</th>\n",
       "      <th>U.S. Landed Costs of Saudi Arabian Light Crude Oil isa4990008a</th>\n",
       "      <th>BP Arabian Light posted at Ras Tanura.</th>\n",
       "      <th>Crude Oil Prices: Brent ÃÂÃÂ¢ÃÂÃÂÃÂÃÂ Europe  ACOILBRENTEU</th>\n",
       "      <th>Crude Oil Prices: West Texas Intermediate (WTI)  ACOILWTICO</th>\n",
       "      <th> Imported Crude Oil Price (refiner average imported crude oil acquisition cost) (PET.R1300____3.A)</th>\n",
       "      <th>U.S. Crude Oil Domestic Acquisition Cost by Refiners, Annual (PET.R1200____3.A)</th>\n",
       "      <th>Dubai Crude Oil Price opendataforafrica.org/IMFPCP2014Jan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 1861</td>\n",
       "      <td> 0.49</td>\n",
       "      <td> 0.49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> 1862</td>\n",
       "      <td> 1.05</td>\n",
       "      <td> 1.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> 1863</td>\n",
       "      <td> 3.15</td>\n",
       "      <td> 3.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> 1864</td>\n",
       "      <td> 8.06</td>\n",
       "      <td> 8.06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> 1865</td>\n",
       "      <td> 6.59</td>\n",
       "      <td> 6.59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Date  BP us dollar of the day  \\\n",
       "0  1861                     0.49   \n",
       "1  1862                     1.05   \n",
       "2  1863                     3.15   \n",
       "3  1864                     8.06   \n",
       "4  1865                     6.59   \n",
       "\n",
       "   US Domestic Oil Price (US $) PET_F000000__3_A  \\\n",
       "0                                           0.49   \n",
       "1                                           1.05   \n",
       "2                                           3.15   \n",
       "3                                           8.06   \n",
       "4                                           6.59   \n",
       "\n",
       "   U.S. Landed Costs of Saudi Arabian Light Crude Oil isa4990008a  \\\n",
       "0                                                NaN                \n",
       "1                                                NaN                \n",
       "2                                                NaN                \n",
       "3                                                NaN                \n",
       "4                                                NaN                \n",
       "\n",
       "   BP Arabian Light posted at Ras Tanura.  \\\n",
       "0                                     NaN   \n",
       "1                                     NaN   \n",
       "2                                     NaN   \n",
       "3                                     NaN   \n",
       "4                                     NaN   \n",
       "\n",
       "   Crude Oil Prices: Brent ÃÂÃÂ¢ÃÂÃÂÃÂÃÂ Europe  ACOILBRENTEU  \\\n",
       "0                                             NaN   \n",
       "1                                             NaN   \n",
       "2                                             NaN   \n",
       "3                                             NaN   \n",
       "4                                             NaN   \n",
       "\n",
       "   Crude Oil Prices: West Texas Intermediate (WTI)  ACOILWTICO  \\\n",
       "0                                                NaN             \n",
       "1                                                NaN             \n",
       "2                                                NaN             \n",
       "3                                                NaN             \n",
       "4                                                NaN             \n",
       "\n",
       "    Imported Crude Oil Price (refiner average imported crude oil acquisition cost) (PET.R1300____3.A)  \\\n",
       "0                                                NaN                                                    \n",
       "1                                                NaN                                                    \n",
       "2                                                NaN                                                    \n",
       "3                                                NaN                                                    \n",
       "4                                                NaN                                                    \n",
       "\n",
       "   U.S. Crude Oil Domestic Acquisition Cost by Refiners, Annual (PET.R1200____3.A)  \\\n",
       "0                                                NaN                                 \n",
       "1                                                NaN                                 \n",
       "2                                                NaN                                 \n",
       "3                                                NaN                                 \n",
       "4                                                NaN                                 \n",
       "\n",
       "   Dubai Crude Oil Price opendataforafrica.org/IMFPCP2014Jan  \n",
       "0                                                NaN          \n",
       "1                                                NaN          \n",
       "2                                                NaN          \n",
       "3                                                NaN          \n",
       "4                                                NaN          "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "dataframe = pandas.read_csv('oil_price.csv')\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interacting with Azure Blobs <a name=\"blobs\"></a>\n",
    "\n",
    "We can also use Azure Storage to store our data. It also makes it pretty straightforward to keep our data private or public. The below code shows using private keys first. Then, in the [shared access](#sharedaccess) section a shared access signature for read-only access is created.\n",
    "\n",
    "\n",
    "Before we can do anything though, we need an Azure Storage Account. Read the [documentation](https://azure.microsoft.com/en-us/documentation/articles/storage-create-storage-account/#create-a-storage-account) article on creating storage accounts or [create a storage account using the Azure SDK](http://azure-sdk-for-python.readthedocs.io/en/latest/resourcemanagementstorage.html#create-storage-account).\n",
    "\n",
    "You can put content into blobs using [AzCopy](https://azure.microsoft.com/en-us/documentation/articles/storage-use-azcopy/) or by using the Python Azure SDK as shown in the example below.\n",
    "\n",
    "Once you retrieve your account and key, you can enter them below.\n",
    "This code will create a container and blob in the azure storage you provide. Then we will read that blob back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "azure_storage_account_name = None\n",
    "azure_storage_account_key = None\n",
    "\n",
    "if azure_storage_account_name is None or azure_storage_account_key is None:\n",
    "    raise Exception(\"You must provide a name and key for an Azure Storage account\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied (use --upgrade to upgrade): azure-storage==0.32.0 in /home/nbcommon/anaconda3_23/lib/python3.4/site-packages\n",
      "Requirement already satisfied (use --upgrade to upgrade): azure-nspkg in /home/nbcommon/anaconda3_23/lib/python3.4/site-packages (from azure-storage==0.32.0)\n",
      "Requirement already satisfied (use --upgrade to upgrade): azure-common in /home/nbcommon/anaconda3_23/lib/python3.4/site-packages (from azure-storage==0.32.0)\n",
      "Requirement already satisfied (use --upgrade to upgrade): python-dateutil in /home/nbcommon/anaconda3_23/lib/python3.4/site-packages (from azure-storage==0.32.0)\n",
      "Requirement already satisfied (use --upgrade to upgrade): requests in /home/nbcommon/anaconda3_23/lib/python3.4/site-packages (from azure-storage==0.32.0)\n",
      "Requirement already satisfied (use --upgrade to upgrade): six>=1.5 in /home/nbcommon/anaconda3_23/lib/python3.4/site-packages (from python-dateutil->azure-storage==0.32.0)\n",
      "\u001b[33mYou are using pip version 8.1.1, however version 8.1.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install azure-storage==0.32.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your text file content would go here"
     ]
    }
   ],
   "source": [
    "from azure.storage.blob import BlockBlobService\n",
    "\n",
    "# First, we need to connect to our blob via the BlobService\n",
    "blob_service = BlockBlobService(azure_storage_account_name, azure_storage_account_key)\n",
    "\n",
    "# Once we are in the account we can create a container\n",
    "blob_service.create_container('azure-notebooks-data')\n",
    "\n",
    "# Insider a container we can create other containers or a blob\n",
    "blob_service.create_blob_from_text('azure-notebooks-data', 'sample.txt', 'your text file content would go here')\n",
    "\n",
    "# There are also methods to list containers and blobs\n",
    "containers = blob_service.list_containers()\n",
    "blobs = blob_service.list_blobs('azure-notebooks-data')\n",
    "\n",
    "# We can also read our blob from azure and get the text.\n",
    "blob_service.get_blob_to_path('azure-notebooks-data', 'sample.txt', 'sample.txt')\n",
    "\n",
    "!cat sample.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Azure Table Storage<a name=\"tablestorage\"></a>\n",
    "\n",
    "Azure Table Storage can be used in much the same way as Blob Storage. Below you will find creating a table in a storage account, adding rows, removing rows, and querying for data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Queried rows after inserts ===\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'PartitionKey': 'testItems',\n",
       "  'RowKey': '0',\n",
       "  'Timestamp': datetime.datetime(2016, 5, 20, 17, 26, 9, 531793, tzinfo=tzlocal()),\n",
       "  'age': 1,\n",
       "  'etag': 'W/\"datetime\\'2016-05-20T17%3A26%3A09.5317932Z\\'\"'},\n",
       " {'PartitionKey': 'testItems',\n",
       "  'RowKey': '10',\n",
       "  'Timestamp': datetime.datetime(2016, 5, 20, 17, 26, 9, 569828, tzinfo=tzlocal()),\n",
       "  'age': 2,\n",
       "  'etag': 'W/\"datetime\\'2016-05-20T17%3A26%3A09.5698289Z\\'\"',\n",
       "  'eyecolor': 'blue'}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Queried rows after delete ===\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'PartitionKey': 'testItems',\n",
       "  'RowKey': '10',\n",
       "  'Timestamp': datetime.datetime(2016, 5, 20, 17, 26, 9, 569828, tzinfo=tzlocal()),\n",
       "  'age': 2,\n",
       "  'etag': 'W/\"datetime\\'2016-05-20T17%3A26%3A09.5698289Z\\'\"',\n",
       "  'eyecolor': 'blue'}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azure.storage.table import TableService\n",
    "import IPython\n",
    "\n",
    "# We start by connecting to our table\n",
    "table_service = TableService(azure_storage_account_name, azure_storage_account_key)\n",
    "\n",
    "# Creating a table in Azure Storage is straightforward\n",
    "table_name = 'azurenotebookstesttable'\n",
    "table_service.create_table(table_name)\n",
    "\n",
    "# You can insert entities to the table\n",
    "entity = {'PartitionKey': 'testItems', 'RowKey': '0', 'age':1}\n",
    "table_service.insert_entity(table_name, entity)\n",
    "table_service.insert_entity(table_name, {'PartitionKey': 'testItems', 'RowKey': '10', 'age':2, 'eyecolor':'blue'})\n",
    "\n",
    "# To query for entities you can use the following code\n",
    "queried_entities = table_service.query_entities(table_name, filter=\"PartitionKey eq 'testItems'\")\n",
    "print('=== Queried rows after inserts ===')\n",
    "IPython.display.display_pretty([i for i in queried_entities])\n",
    "\n",
    "# You can delete an entity by using its partition and row key.\n",
    "\n",
    "table_service.delete_entity(table_name, 'testItems', '0')\n",
    "                                         \n",
    "# We can query to show we have removed the entity\n",
    "queried_entities = table_service.query_entities(table_name, filter=\"PartitionKey eq 'testItems'\")\n",
    "print('=== Queried rows after delete ===')\n",
    "IPython.display.display_pretty([i for i in queried_entities])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Providing Read Only Access to Azure Storage through Shared Access Signatures <a name=\"sharedaccess\"></a>\n",
    "\n",
    "Sometimes you want to share your data but you don't want to give them the ability to edit the dataset. Shared Access Signatures allow you to share your data and provide whatever level of control you want to the receiver. A common use case is to provide read only access to a user so they can read your data but not edit it.\n",
    "\n",
    "Below, we create a shared access signature for our table (this also works with blobs) with read permissions. We show that we can read the table but we show that we can't write. With tables you also need to provide permission to query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Creating a Shared Access Signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'se=2016-05-20T18%3A25%3A13Z&sig=rskxaKrEtnWcvVzfjW2rdofv5gWV9NVLgixH6HbkrK4%3D&sp=r&sv=2015-07-08&sr=b'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azure.storage.blob.models import BlobPermissions\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "sas_token = blob_service.generate_blob_shared_access_signature(\n",
    "    'azure-notebooks-data',\n",
    "    'sample.txt',\n",
    "    BlobPermissions.READ,\n",
    "    datetime.utcnow() + timedelta(hours=1)\n",
    ")\n",
    "\n",
    "sas_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a Shared Access Signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'your text file content would go here'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a service and use the SAS \n",
    "sas_blob_service = BlockBlobService( \n",
    "    account_name=azure_storage_account_name, \n",
    "    sas_token=sas_token,\n",
    ")\n",
    "\n",
    "sas_blob_service.get_blob_to_text('azure-notebooks-data', 'sample.txt').content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning up our blobs and tables <a name=\"cleanup\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally, let's clean up the resources created.\n",
    "# Delete the blob, container, and table we created\n",
    "blob_service.delete_blob('azure-notebooks-data', 'sample.txt')\n",
    "blob_service.delete_container('azure-notebooks-data')\n",
    "table_service.delete_table('azurenotebookstesttable')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using SQL  <a name=\"usingsql\"></a>\n",
    "With the assistance of the pyodbc library we can access our SQL Servers in Microsoft Azure. To create a SQL Server you can see the documentation for [Creating and Using Azure SQL Documentation](https://azure.microsoft.com/en-us/documentation/articles/sql-database-develop-python-simple/).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!pip install pyodbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "\n",
    "server = 'yourserver.database.windows.net'\n",
    "database = 'yourdatabase'\n",
    "username = 'yourusername'\n",
    "password = 'yourpassword'\n",
    "\n",
    "driver= '{ODBC Driver 13 for SQL Server}'\n",
    "cnxn = pyodbc.connect('DRIVER='+driver+';PORT=1433;SERVER='+server+';PORT=1443;DATABASE='+database+';UID='+username+';PWD='+ password)\n",
    "cursor = cnxn.cursor()\n",
    "cursor.execute(\"select @@VERSION\")\n",
    "row = cursor.fetchone()\n",
    "if row:\n",
    "    print row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#PYMSSQL --> NOTE the connection parameter settings for pymssql are different from pyodbc above. \n",
    "#pymssql.connect(\"xxx.database.windows.net\", \"username@xxx\", \"password\", \"db_name\")\n",
    "#see details : http://pymssql.org/en/latest/azure.html\n",
    "\n",
    "import pymssql\n",
    "conn = pymssql.connect(\"yourserver.database.windows.net\", \"yourusername@yourserver\", \"yourpassword\", \"yourdatabase\")\n",
    "cursor2 = conn.cursor()\n",
    "cursor2.execute(\"select @@VERSION\")\n",
    "row = cursor2.fetchone()\n",
    "if row:\n",
    "    print( row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Resources <a name=\"otherways\"></a>\n",
    "\n",
    "This notebook does not show all possible ways you can access your data. Below are a few other examples of how you may access data. \n",
    "\n",
    "### Links\n",
    "\n",
    "[Azure Data Factory](https://azure.microsoft.com/en-us/services/data-factory/)\n",
    "\n",
    "[Copy Wizard for Azure Data Factory](https://azure.microsoft.com/en-us/updates/code-free-copy-wizard-for-azure-data-factory/)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
